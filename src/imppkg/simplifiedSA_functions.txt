
# def import_df(filepath: str) -> pd.DataFrame: 
#     # This function exists (rather than having the user do it themselves) bc we are not using pandas, we're using modin as pd


# def download_df(df_obj: pd.DataFrame, title: str, save_filepath="./", filename_suffix='_save', nodate=True):
#     '''
#     INPUT: DataFrame object and suffix to add to output csv filename
#     OUTPUT: Write DataFrame object to csv file (both temp VM and download)
#     '''
 

# def import_text(filepath: str) -> str: # TODO: change name to import_text
#     '''
#     Parameter(s):
#     uploaded: dictionary with filename as key and properly formatted text body as value (should have just one key-value pair)
#     novel_title_str: [Title] by [Author] (string)
#     '''
  
# def preview(something) -> str: # would make more sense as a method imo. could take in an SAtext object and be a method, or take in a dict to be able to print the file name
#     # Return string showing beginning and end of text for user verification, or show some clean text lines from a df
#     # input can be a string or a df
 

# def gutenberg_import(Novel_Title: str, Gutenberg_URL: str, 
#                     sentence_first_str = None, sentence_last_str = None) -> list:
#     #@title Enter the URL of your novel at ***gutenberg.net.au***
#     #@markdown Paste the URL to the ***HTML version*** (not plain text).

#     # Novel_Title = 'Frankenstein by Mary Shelley'  #@param {type: "string"}

#     # Gutenberg_URL = 'https://gutenberg.net.au/ebooks/z00006.html'  #@param {type: "string"}
#     # the first sentence in the body of your novel: sentence_first_str
#     # the last sentence in the body of your novel: sentence_last_str


# def segment_sentences(novel_raw_str:  str) -> list: # TODO: don't print/have a verification string if there aren't parameters to adjust here
#     # Segment by sentence
   

# def clean_string(dirty_str: str) -> str: # to be called within create_df_with_text (formerly known as clean_text)
#     #TODO: add options, and add more functions in here that take care of stuff clean-text doesn't, like emoticons
#     '''
#     INPUT: a raw string
#     OUTPUT: a clean string
#     '''

#     contraction_expanded_str = contractions.fix(dirty_str)

#     clean_str = clean(contraction_expanded_str, # TODO: detemine if we want to keep this dependency (clean-text). Chun says no. Find alternative?
#         fix_unicode=True,               # fix various unicode errors
#         to_ascii=True,                  # transliterate to closest ASCII representation
#         lower=True,                     # lowercase text
#         no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them
#         no_urls=False,                  # replace all URLs with a special token
#         no_emails=False,                # replace all email addresses with a special token
#         no_phone_numbers=False,         # replace all phone numbers with a special token
#         no_numbers=False,               # replace all numbers with a special token
#         no_digits=False,                # replace all digits with a special token
#         no_currency_symbols=False,      # replace all currency symbols with a special token
#         no_punct=False,                 # remove punctuation
#         # replace_with_punct="",          # instead of removing punctuations, you may replace them
#         # replace_with_url="<URL>",
#         # replace_with_email="<EMAIL>",
#         # replace_with_phone_number="<PHONE>",
#         # replace_with_number="<NUMBER>",
#         # replace_with_digit="0",
#         # replace_with_currency_symbol="<CUR>",
#         lang="en"                       # set to 'de' for German special handling
#     )

#     # Replace all new lines/returns with single whitespace
#     # clean_str = clean_str.replace('\n\r', ' ') # I think these are commented out bc clean() with no_line_breaks=True already does those
#     # clean_str = clean_str.replace('\n', ' ')
#     # clean_str = clean_str.replace('\r', ' ')
#     clean_str = ' '.join(clean_str.split()) # remove leading, trailing, and repeated spaces

#     return clean_str 


# def create_clean_df(novel_sentences_ls: list, novel_title: str) -> pd.DataFrame:
#     # Create sentiment_df to hold text sentences and corresponding sentiment values
  

# def vader(sentiment_df: pd.DataFrame, novel_title: str) ->  pd.DataFrame:
   

# def textblob(sentiment_df: pd.DataFrame, novel_title: str) -> pd.DataFrame:
   
        
        
# def distilbert(sentiment_df: pd.DataFrame, novel_title: str) -> pd.DataFrame:
    


# def combine_model_results(sentiment_df: pd.DataFrame, novel_title, **kwargs) -> pd.DataFrame:
#     '''
#     Optional named args: vader = vader_df, textblob = textblob_df, 
#                          distilbert = distilbert_df, nlptown = nlptown_df, 
#                          roberta15lg = roberta15lg_df
#     '''
  


# def plot_raw_sentiments(sentiment_all_df: pd.DataFrame, title: str, save_filepath="./", 
#                         window_pct = 10,
#                         models = ['vader', 'textblob', 'distilbert']):
#     '''
#     window_pct: between 1 & 20, inclusive
#     '''
   

# def plot_normalized_sentiments(sentiment_all_df: pd.DataFrame, title: str, save_filepath="./", window_pct = 10,
#                                models = ['vader', 'textblob', 'distilbert']):
#     '''@param models: must contain models with the same timesereies length 
#     (sentimentR cannot be included without adjustments â€” used to be model_samelen_ls)
    
#     This function normalizes the sentiments in the given models and saves a png plot of them'''
    
 